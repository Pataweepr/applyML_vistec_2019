{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw7-Transfer_Learning(student)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pataweepr/applyML_vistec_2019/blob/master/hw7_Transfer_Learning(student).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "NraKJzK-KiaM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning for image classification\n",
        "In this lab, we are going to explore a few options to train models for image classification.\n",
        "We will use [17 Category Flower Dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/17/) throughout this lab."
      ]
    },
    {
      "metadata": {
        "id": "aQ3DsF1qVSZY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we will mount the dataset to this notebook.\n",
        "Add this [zip file](https://drive.google.com/open?id=1UCRGAy6hin1Uhsscn150zVvGgKiaePmJ) to your google drive (by clicking google drive symbol on the top-right) and change the unzip path accordingly: \n",
        "\n",
        "The following command will mount your google drive to the local machine this notebook is running on. Authorize the mounting and then unzip the dataset. \n",
        "\n",
        "It should take a while to unzip."
      ]
    },
    {
      "metadata": {
        "id": "qXTCU2C8s2Rw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KZFpwXRLs2Wi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip '/content/gdrive/My Drive/lab3-nvidia-chula.zip' > /dev/nul"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v94NJcpZ9JEq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import python libraries"
      ]
    },
    {
      "metadata": {
        "id": "YkYmiK2cHKuQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are downgrading Pillow. This will require you to **restart the runtime** after the following code block is done."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RJnI-T_7vF-I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Downgrade Pillow to avoid errors\n",
        "!pip install Pillow==3.4.2\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras import optimizers \n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
        "from time import time\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(12)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(12)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.random.seed(12)\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "from keras import backend as K\n",
        "# This is called to clear the original model session in order to use TensorBoard\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LRst56javF-N"
      },
      "cell_type": "markdown",
      "source": [
        "## Variable path Setting\n",
        "- training, validation, testing and model path directories."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DEqnBgfrvF-P",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dir = \"./dataset/lab3-1/10_flower/train\"\n",
        "val_dir = \"./dataset/lab3-1/10_flower/validate\"\n",
        "test_dir = \"./dataset/lab3-1/10_flower/test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "h9nVSt8MvF-T"
      },
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "\n",
        "Read training and validation dataset\n",
        "\n",
        "### Data augmentation strategies using ImageDataGenerator\n",
        "\n",
        "Keras has automatic [data augmentation](https://keras.io/preprocessing/image/) for images. Data augmentation helps increase the amount of training data and help reduce overfitting of the model. Image generator also helps manage the loading of data to reduce the amount of memory required. An example usage is shown below.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "df2uqfefvF-U",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_size = 224\n",
        "num_class = 10\n",
        "\n",
        "batch_size=32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        " \n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(224,224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLsvhBqg8FC-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the code above, what kind of data augmentation is being done?\n",
        "\n",
        "**Ans: **"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QaKccrNIvF-Y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x, y = train_generator.next()\n",
        "print(x.shape,y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xC0RwYqF9K1a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Describe what each dimension of x and y is\n",
        "\n",
        "**Ans:**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "JVIQaweKvF-a"
      },
      "cell_type": "markdown",
      "source": [
        "## Modeling\n",
        "\n",
        "The base model (model architecture) we will used is called VGG19. The `VGG19` model are pre-trained on `ImageNet`. You can read more about VGG19 in [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)\n",
        "\n",
        "We can start with these pretrained weights when training on our new task by using it only as a feature extractor. That means that we freeze every layer prior to the output layer and simply learn a new output layer.\n",
        "\n",
        "To fine-tune a network, we must first replace the last fully-connected layer with a new one that outputs the desired number of classes. We initialize its weights randomly. Then we continue training as normal. Sometimes it’s common to use a smaller learning rate based on the intuition that we may already be close to a good result.\n",
        "\n",
        "In this demonstration, we’ll fine-tune a model pretrained on `VGG19` to the smaller target task and train the model with checkpoints and early stopping callbacks."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "C3YwoAZavF-b"
      },
      "cell_type": "markdown",
      "source": [
        "Define f1_score metric for evaluating model "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1OAXNB5ZvF-b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def f1_score_metric(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, \"int32\")\n",
        "    y_pred = tf.cast(tf.round(y_pred), \"int32\") # implicit 0.5 threshold via tf.round\n",
        "    y_correct = y_true * y_pred\n",
        "    sum_true = tf.reduce_sum(y_true, axis=1)\n",
        "    sum_pred = tf.reduce_sum(y_pred, axis=1)\n",
        "    sum_correct = tf.reduce_sum(y_correct, axis=1)\n",
        "    precision = sum_correct / sum_pred\n",
        "    recall = sum_correct / sum_true\n",
        "    f_score = 5 * precision * recall / (4 * precision + recall)\n",
        "    f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
        "    return tf.reduce_mean(f_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Iwqm8TpovF-d"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 1 (No pre-training)\n",
        "- VGG19 (random initialized weights) + 2 Dense layers + Output layer"
      ]
    },
    {
      "metadata": {
        "id": "OrUXw4Gx2-sW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "84qeqgLWvF-d",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_model = VGG19(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_class, activation='softmax')(x)\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
        "                                verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
        "                           patience=30, verbose=0, mode='max')\n",
        "\n",
        "model_1_path = \"./model/lab3_1/{}.h5\".format(\"model_1\")\n",
        "checkpoint = ModelCheckpoint(model_1_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
        "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
        "\n",
        "# Create and compile model\n",
        "model_1 = Model(inputs=base_model.input, outputs=output)\n",
        "model_1.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=0.0001),metrics=[\"accuracy\", f1_score_metric])\n",
        "\n",
        "# Load last epoch model\n",
        "# We have already trained the model for a certain amount of iterations.\n",
        "# Otherwise, this will take too long.\n",
        "pretrined_model_1_path = \"./model/const_models/lab3_1/model_1.h5\"\n",
        "model_1.load_weights(pretrined_model_1_path)\n",
        "\n",
        "## Run until early stopping\n",
        "num_training_img=240\n",
        "num_validation_img=80\n",
        "stepsPerEpoch = num_training_img/batch_size\n",
        "validationSteps= num_validation_img/batch_size\n",
        "model_1.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=stepsPerEpoch,\n",
        "        epochs=5,\n",
        "        callbacks = callbacks_list,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps=validationSteps\n",
        "        )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7KQZCDYy_Tlj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "base_model = VGG19(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_class, activation='softmax')(x)\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
        "                                verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
        "                           patience=30, verbose=0, mode='max')\n",
        "\n",
        "model_1_path = \"./model/lab3_1/{}.h5\".format(\"model_1\")\n",
        "checkpoint = ModelCheckpoint(model_1_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
        "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
        "\n",
        "# Create and compile model\n",
        "model_1 = Model(inputs=base_model.input, outputs=output)\n",
        "model_1.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=0.0001),metrics=[\"accuracy\", f1_score_metric])\n",
        "\n",
        "# Load last epoch model\n",
        "pretrined_model_1_path = \"./model/const_models/lab3_1/model_1.h5\"\n",
        "model_1.load_weights(pretrined_model_1_path)\n",
        "\n",
        "## Run until early stopping\n",
        "num_training_img=240\n",
        "num_validation_img=80\n",
        "stepsPerEpoch = num_training_img/batch_size\n",
        "validationSteps= num_validation_img/batch_size\n",
        "model_1.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=stepsPerEpoch,\n",
        "        epochs=5,\n",
        "        callbacks = callbacks_list,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps=validationSteps\n",
        "        )\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "metadata": {
        "id": "neARrHMNF1bE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice how there are three callbacks in the code. Explain each of them\n",
        "\n",
        "** Ans: **"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YqSrSNz5vF-f"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 2 (with frozen pre-trained weights)\n",
        "- VGG (pre-trained weights) + 2 Dense layers + Output layer\n",
        "- Freezes all weights of base model layers"
      ]
    },
    {
      "metadata": {
        "id": "_gMpWvTa2_7e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Mj-OouKhvF-h",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_class, activation='softmax')(x)\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
        "                                verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
        "                           patience=20, verbose=0, mode='max')\n",
        "\n",
        "model_2_path = \"./model/lab3_1/{}.h5\".format(\"model_2\")\n",
        "checkpoint = ModelCheckpoint(model_2_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
        "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
        "\n",
        "# Create and compile model\n",
        "model_2 = Model(inputs=base_model.input, outputs=output)\n",
        "model_2.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=0.0001),metrics=[\"accuracy\", f1_score_metric])\n",
        "\n",
        "# Load last epoch model\n",
        "pretrined_model_2_path = \"./model/const_models/lab3_1/model_2.h5\"\n",
        "model_2.load_weights(pretrined_model_2_path)\n",
        "\n",
        "## Run until early stopping\n",
        "num_training_img=240\n",
        "num_validation_img=80\n",
        "stepsPerEpoch = num_training_img/batch_size\n",
        "validationSteps= num_validation_img/batch_size\n",
        "model_2.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=stepsPerEpoch,\n",
        "        epochs=5,\n",
        "        callbacks = callbacks_list,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps=validationSteps\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xiYDY7CF_hY5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_class, activation='softmax')(x)\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
        "                                verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
        "                           patience=20, verbose=0, mode='max')\n",
        "\n",
        "model_2_path = \"./model/lab3_1/{}.h5\".format(\"model_2\")\n",
        "checkpoint = ModelCheckpoint(model_2_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
        "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
        "\n",
        "# Create and compile model\n",
        "model_2 = Model(inputs=base_model.input, outputs=output)\n",
        "model_2.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=0.0001),metrics=[\"accuracy\", f1_score_metric])\n",
        "\n",
        "# Load last epoch model\n",
        "pretrined_model_2_path = \"./model/const_models/lab3_1/model_2.h5\"\n",
        "model_2.load_weights(pretrined_model_2_path)\n",
        "\n",
        "## Run until early stopping\n",
        "num_training_img=240\n",
        "num_validation_img=80\n",
        "stepsPerEpoch = num_training_img/batch_size\n",
        "validationSteps= num_validation_img/batch_size\n",
        "model_2.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=stepsPerEpoch,\n",
        "        epochs=5,\n",
        "        callbacks = callbacks_list,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps=validationSteps\n",
        "        )\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EbG3IzNHvF-j"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 3 (with adaptable pre-trained weights)\n",
        "- VGG19 (pre-trained weights) + 2 Dense layers + Output layer\n",
        "- use basic Fine-tuning technique which unfreezes all layers."
      ]
    },
    {
      "metadata": {
        "id": "IoZqDEnr3BNp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gE6wHaM6vF-k",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_class, activation='softmax')(x)\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
        "                                verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
        "                           patience=30, verbose=0, mode='max')\n",
        "\n",
        "model_3_path = \"./model/lab3_1/{}.h5\".format(\"model_3\")\n",
        "checkpoint = ModelCheckpoint(model_3_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
        "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
        "\n",
        "# Create and compile model\n",
        "model_3 = Model(inputs=base_model.input, outputs=output)\n",
        "model_3.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=0.00001),metrics=[\"accuracy\", f1_score_metric])\n",
        "\n",
        "# Load last epoch model\n",
        "pretrined_model_3_path = \"./model/const_models/lab3_1/model_3.h5\"\n",
        "model_3.load_weights(pretrined_model_3_path)\n",
        "\n",
        "## Run until early stopping\n",
        "num_training_img=240\n",
        "num_validation_img=80\n",
        "stepsPerEpoch = num_training_img/batch_size\n",
        "validationSteps= num_validation_img/batch_size\n",
        "history = model_3.fit_generator(\n",
        "                    train_generator,\n",
        "                    steps_per_epoch=stepsPerEpoch,\n",
        "                    epochs=5,\n",
        "                    callbacks = callbacks_list,\n",
        "                    validation_data = validation_generator,\n",
        "                    validation_steps=validationSteps\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z53Lhl8f_psd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_class, activation='softmax')(x)\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
        "                                verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
        "                           patience=30, verbose=0, mode='max')\n",
        "\n",
        "model_3_path = \"./model/lab3_1/{}.h5\".format(\"model_3\")\n",
        "checkpoint = ModelCheckpoint(model_3_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
        "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
        "\n",
        "# Create and compile model\n",
        "model_3 = Model(inputs=base_model.input, outputs=output)\n",
        "model_3.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=0.00001),metrics=[\"accuracy\", f1_score_metric])\n",
        "\n",
        "# Load last epoch model\n",
        "pretrined_model_3_path = \"./model/const_models/lab3_1/model_3.h5\"\n",
        "model_3.load_weights(pretrined_model_3_path)\n",
        "\n",
        "## Run until early stopping\n",
        "num_training_img=240\n",
        "num_validation_img=80\n",
        "stepsPerEpoch = num_training_img/batch_size\n",
        "validationSteps= num_validation_img/batch_size\n",
        "history = model_3.fit_generator(\n",
        "                    train_generator,\n",
        "                    steps_per_epoch=stepsPerEpoch,\n",
        "                    epochs=5,\n",
        "                    callbacks = callbacks_list,\n",
        "                    validation_data = validation_generator,\n",
        "                    validation_steps=validationSteps\n",
        "                    )\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "W5dR04YTvF-m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for f1_score\n",
        "plt.plot(history.history['f1_score_metric'])\n",
        "plt.plot(history.history['val_f1_score_metric'])\n",
        "plt.title('model f1_score_metric')\n",
        "plt.ylabel('f1_score_metric')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SL381I2S_0rQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for f1_score\n",
        "plt.plot(history.history['f1_score_metric'])\n",
        "plt.plot(history.history['val_f1_score_metric'])\n",
        "plt.title('model f1_score_metric')\n",
        "plt.ylabel('f1_score_metric')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bANkwLRsvF-n"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 4 (with chain-taw)\n",
        "- VGG (pre-trained weights) + 2 Dense layers + Output layer\n",
        "- use `Chain-thaw` Fine-tuning technique, referenced by [Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm](https://arxiv.org/pdf/1708.00524.pdf)."
      ]
    },
    {
      "metadata": {
        "id": "G_dqgaJ33CzZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WDcx1kJkvF-o",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_class, activation='softmax')(x)\n",
        "\n",
        "# Create  model\n",
        "model_4 = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "num_training_img=240\n",
        "num_validation_img=80\n",
        "stepsPerEpoch = num_training_img/batch_size\n",
        "validationSteps= num_validation_img/batch_size\n",
        "\n",
        "base_model_layers = model_4.layers[:23]\n",
        "new_model_layers =  model_4.layers[23:]\n",
        "\n",
        "base_model_blocks = {\n",
        "    0: base_model_layers[1:3],\n",
        "    1: base_model_layers[4:6],\n",
        "    2: base_model_layers[7:11],\n",
        "    3: base_model_layers[12:16],\n",
        "    4: base_model_layers[17:21]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHu1c4hoABhL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_class, activation='softmax')(x)\n",
        "\n",
        "# Create  model\n",
        "model_4 = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "num_training_img=240\n",
        "num_validation_img=80\n",
        "stepsPerEpoch = num_training_img/batch_size\n",
        "validationSteps= num_validation_img/batch_size\n",
        "\n",
        "base_model_layers = model_4.layers[:23]\n",
        "new_model_layers =  model_4.layers[23:]\n",
        "\n",
        "base_model_blocks = {\n",
        "    0: base_model_layers[1:3],\n",
        "    1: base_model_layers[4:6],\n",
        "    2: base_model_layers[7:11],\n",
        "    3: base_model_layers[12:16],\n",
        "    4: base_model_layers[17:21]\n",
        "}\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "04nhLybNvF-r",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"\\n--[Phase 1]--: Train only new layers\")\n",
        "\n",
        "for layer in base_model_layers:\n",
        "   layer.trainable = False\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
        "                               verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
        "                          patience=25, verbose=0, mode='max')\n",
        "\n",
        "model_4_path = os.path.abspath(os.path.join(\"./model/const_models/lab3_1/{}.h5\".format(\"model_4_1\")))\n",
        "checkpoint = ModelCheckpoint(model_4_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
        "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
        "\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=optimizers.Adam(lr=0.0001), metrics=[\"accuracy\", f1_score_metric])\n",
        "\n",
        "model_4.fit_generator(\n",
        "   train_generator,\n",
        "   steps_per_epoch=stepsPerEpoch,\n",
        "   epochs=50,\n",
        "   callbacks=callbacks_list,\n",
        "   validation_data=validation_generator,\n",
        "   validation_steps=validationSteps\n",
        "   )\n",
        "\n",
        "model_4_weight_path = \"./model/lab3_1/{}.h5\".format(\"model_4_1\")\n",
        "model_4.save_weights(model_4_weight_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FfH5cStyAGEQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "print(\"\\n--[Phase 1]--: Train only new layers\")\n",
        "\n",
        "for layer in base_model_layers:\n",
        "   layer.trainable = False\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
        "                               verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
        "                          patience=25, verbose=0, mode='max')\n",
        "\n",
        "model_4_path = os.path.abspath(os.path.join(\"./model/const_models/lab3_1/{}.h5\".format(\"model_4_1\")))\n",
        "checkpoint = ModelCheckpoint(model_4_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
        "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
        "\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=optimizers.Adam(lr=0.0001), metrics=[\"accuracy\", f1_score_metric])\n",
        "\n",
        "model_4.fit_generator(\n",
        "   train_generator,\n",
        "   steps_per_epoch=stepsPerEpoch,\n",
        "   epochs=50,\n",
        "   callbacks=callbacks_list,\n",
        "   validation_data=validation_generator,\n",
        "   validation_steps=validationSteps\n",
        "   )\n",
        "\n",
        "model_4_weight_path = \"./model/lab3_1/{}.h5\".format(\"model_4_1\")\n",
        "model_4.save_weights(model_4_weight_path)\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZbXYGkf_vF-t",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"\\n--[Phase 2]--: Train every CNN blocks of base model (5 blocks)\")\n",
        "\n",
        "model_4_prev_path = os.path.abspath(os.path.join(\"./model/const_models/lab3_1/model_4_1.h5\"))\n",
        "print(\"Loading the previous weight from {}.\".format(model_4_prev_path))\n",
        "model_4.load_weights(model_4_prev_path)\n",
        "\n",
        "for layer in new_model_layers:\n",
        "   layer.trainable = False\n",
        "\n",
        "for idx in range(0, 5):\n",
        "  # train idx block\n",
        "  print(\"[Train block{}]: containing {} layers\".format(idx, len(base_model_blocks[idx])))\n",
        "\n",
        "  # Callbacks\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=4,\n",
        "                                 verbose=1, min_delta=0.0001, cooldown=2, min_lr=0)\n",
        "  early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
        "                            patience=10, verbose=0, mode='max')\n",
        "\n",
        "  model_4_path = os.path.abspath(os.path.join(f\"./model/const_models/lab3_1/model_4_2_{idx}.h5\"))\n",
        "  checkpoint = ModelCheckpoint(model_4_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
        "  callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
        "\n",
        "  for layer in base_model_layers:\n",
        "    if layer in base_model_blocks[idx]:\n",
        "      layer.trainable = True\n",
        "      print(\"train {}\".format(layer))\n",
        "    else:\n",
        "       layer.trainable = False\n",
        "  model_4.compile(loss=\"categorical_crossentropy\",\n",
        "               optimizer=optimizers.Adam(lr=0.000001), metrics=[\"accuracy\", f1_score_metric])\n",
        "  model_4.fit_generator(\n",
        "     train_generator,\n",
        "     steps_per_epoch=stepsPerEpoch,\n",
        "     epochs=50,\n",
        "     callbacks=callbacks_list,\n",
        "     validation_data=validation_generator,\n",
        "     validation_steps=validationSteps\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6VYdHXOYAPet",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "print(\"\\n--[Phase 2]--: Train every CNN blocks of base model (5 blocks)\")\n",
        "\n",
        "model_4_prev_path = os.path.abspath(os.path.join(\"./model/const_models/lab3_1/model_4_1.h5\"))\n",
        "print(\"Loading the previous weight from {}.\".format(model_4_prev_path))\n",
        "model_4.load_weights(model_4_prev_path)\n",
        "\n",
        "for layer in new_model_layers:\n",
        "   layer.trainable = False\n",
        "\n",
        "for idx in range(0, 5):\n",
        "  # train idx block\n",
        "  print(\"[Train block{}]: containing {} layers\".format(idx, len(base_model_blocks[idx])))\n",
        "\n",
        "  # Callbacks\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=4,\n",
        "                                 verbose=1, min_delta=0.0001, cooldown=2, min_lr=0)\n",
        "  early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
        "                            patience=10, verbose=0, mode='max')\n",
        "\n",
        "  model_4_path = os.path.abspath(os.path.join(f\"./model/const_models/lab3_1/model_4_2_{idx}.h5\"))\n",
        "  checkpoint = ModelCheckpoint(model_4_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
        "  callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
        "\n",
        "  for layer in base_model_layers:\n",
        "    if layer in base_model_blocks[idx]:\n",
        "      layer.trainable = True\n",
        "      print(\"train {}\".format(layer))\n",
        "    else:\n",
        "       layer.trainable = False\n",
        "  model_4.compile(loss=\"categorical_crossentropy\",\n",
        "               optimizer=optimizers.Adam(lr=0.000001), metrics=[\"accuracy\", f1_score_metric])\n",
        "  model_4.fit_generator(\n",
        "     train_generator,\n",
        "     steps_per_epoch=stepsPerEpoch,\n",
        "     epochs=50,\n",
        "     callbacks=callbacks_list,\n",
        "     validation_data=validation_generator,\n",
        "     validation_steps=validationSteps\n",
        "  )\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pnDsGi4JvF-v"
      },
      "cell_type": "markdown",
      "source": [
        "## `To do` \n",
        "\n",
        "You are supposed to implement `Chain-thaw` Fine-tuning technique in the last phase which is to unfreeze all of model layers and train it to be well adapted to the target task.\n",
        "\n",
        "HINT: you should load the last epoch model weights from provided const-model folder before training model with `fit_generator` function from the code below.\n",
        "\n",
        "\n",
        "```python\n",
        "pretrined_model_4_path = \"./model/const_models/lab3_1/model_4_3.h5\"\n",
        "model_4.load_weights(pretrined_model_4_path)\n",
        "```\n",
        "\n",
        "\n",
        "Noted that there are still needs for both `ModelCheckpoint` callback, saving model to the path, and `EarlyStopping` is still required.\n",
        "\n",
        "The solution can be seen in the cell below."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "y2jZ56jRvF-w",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"--[Phase 3]--: Train all layers\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kss1HVXevF-0"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "-  `F-score` is really useful if you want to compare 2 classifiers. It is computed using the harmonic mean of precision and recall, and gives much more weight to low values. As a result of that, the classifier will only get a high F-score, if both recall and precision are high. You can easily compute the F-Score with sklearn.\n",
        "- `Micro F1-score` is to calculate metrics globally by counting the total true positives, false negatives and false positives, while \n",
        "- `Macro F1-score` is to calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JKoWdqBfvF_D",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_to_idx = train_generator.class_indices\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aIBe9S-9vF_H",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx_to_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PvdsA51y_53t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls ./model/lab3_1/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "T3taxJbSvF_N",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model_1_path = \"./model/lab3_1/{}.h5\".format(\"model_1\")\n",
        "model_2_path = \"./model/lab3_1/{}.h5\".format(\"model_2\")\n",
        "model_3_path = \"./model/lab3_1/{}.h5\".format(\"model_3\")\n",
        "model_4_path = \"./model/lab3_1/{}.h5\".format(\"model_4_1\")\n",
        "\n",
        "model_1.load_weights(model_1_path)\n",
        "model_2.load_weights(model_2_path)\n",
        "model_3.load_weights(model_3_path)\n",
        "model_4.load_weights(model_4_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CDENRYG7vF_R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This code just run the 4 models on the test set.\n",
        "\n",
        "idx_to_model = {\n",
        "    1: model_1,\n",
        "    2: model_2,\n",
        "    3: model_3,\n",
        "    4: model_4\n",
        "}\n",
        "idx_to_preds = {\n",
        "    1: ([], []), # y_trues, y_preds\n",
        "    2: ([], []),\n",
        "    3: ([], []),\n",
        "    4: ([], [])\n",
        "}\n",
        "\n",
        "for class_idx in tqdm(range(num_class)):\n",
        "    label = idx_to_class[class_idx]\n",
        "    file_list = glob.glob(\"{}/{}/*.jpg\".format(test_dir, label))\n",
        "    for raw_image in file_list:\n",
        "        inputShape = (224,224) # Assumes 3 channel image\n",
        "        image = load_img(raw_image, target_size=inputShape)\n",
        "        image = img_to_array(image)   # shape is (224,224,3)\n",
        "        image = preprocess_input(image)\n",
        "        image = np.expand_dims(image, axis=0)  # Now shape is (1,224,224,3)\n",
        "\n",
        "        for model_idx in range(1,5):\n",
        "            model = idx_to_model[model_idx]\n",
        "            preds = model.predict(image)\n",
        "            pred_class = np.argmax(preds)\n",
        "\n",
        "            # append y_trues\n",
        "            idx_to_preds[model_idx][0].append(class_idx)\n",
        "            # append y_preds\n",
        "            idx_to_preds[model_idx][1].append(pred_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y5poi6kS0fza",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    print(\"Performace of each models:\")\n",
        "    for idx in range(1, 5):\n",
        "      \n",
        "        y_trues = idx_to_preds[idx][0]\n",
        "        y_preds = idx_to_preds[idx][1]\n",
        "        print(\"-- Model_{} (acc:{:.4f}, f1_micro:{:.4f}, f1_macro:{:.4f})\".format(idx,\n",
        "                                                                                accuracy_score(y_trues, y_preds), \n",
        "                                                                                f1_score(y_trues, y_preds, average='micro'),\n",
        "                                                                                f1_score(y_trues, y_preds, average='macro')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZZPkN7-eGeji",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the results, what gives the biggest gain in accuracy?\n",
        "\n",
        "** Ans: **"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "iG0KyrMvvF_W"
      },
      "cell_type": "markdown",
      "source": [
        "## Result\n",
        "To see how the model performs for the testing samples, we can visualize them using matplotlib."
      ]
    },
    {
      "metadata": {
        "id": "R-uWaRiw0fzj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "for class_idx in random.sample(range(0, num_class), 3):\n",
        "    label = idx_to_class[class_idx]\n",
        "    file_list = glob.glob(\"{}/{}/*.jpg\".format(test_dir, label))\n",
        "    for raw_image in file_list[:2]:\n",
        "        inputShape = (224,224)\n",
        "        image = load_img(raw_image, target_size=inputShape)\n",
        "        image = img_to_array(image)\n",
        "        image = preprocess_input(image)\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "\n",
        "        preds = model_4.predict(image)\n",
        "\n",
        "        pred_class = np.argmax(preds)\n",
        "        pred_label = idx_to_class[pred_class]\n",
        "\n",
        "        title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
        "            label,\n",
        "            pred_label,\n",
        "            preds[0][pred_class])\n",
        "\n",
        "        original = load_img(raw_image, target_size=(224, 224))\n",
        "        plt.figure(figsize=[3,3])\n",
        "        plt.axis('off')\n",
        "        plt.title(title)\n",
        "        plt.imshow(original)\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}