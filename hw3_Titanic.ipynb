{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3_Titanic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pataweepr/applyML_vistec_2019/blob/master/hw3_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "G6CGOezHSexx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Titanic\n",
        "\n",
        "พวกเราจะพยายามให้ logictic reg เพื่อทำนาย แบบจำลอง\n",
        "\n",
        "[kaggle](https://www.kaggle.com/c/titanic)\n",
        "\n",
        "[linear_model](https://scikit-learn.org/stable/modules/linear_model.html)\n",
        "\n",
        "[confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
        "\n",
        "[link](https://stackoverflow.com/questions/49310470/using-kaggle-datasets-into-google-colab)\n",
        "\n",
        "[seaborn](https://seaborn.pydata.org/)"
      ]
    },
    {
      "metadata": {
        "id": "ki92RGEezm_l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import library \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,mean_squared_error\n",
        "from google.colab import files\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import display\n",
        "import json\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ye4x4gpbD2kq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97HFwuM0D4NG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip '/content/gdrive/My Drive/house-prices-advanced-regression-techniques.zip'\n",
        "!ls\n",
        "\n",
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "display(sample_submission.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xNREUG6BENPj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('train.csv')\n",
        "train_data, val_data = train_test_split(train_data, test_size=1/11, random_state=30)\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "display(train_data.shape)\n",
        "display(val_data.shape)\n",
        "display(test_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0QqbtbriEjcf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "LotFrontage\n",
        "GarageYrBlt\n",
        "MasVnrArea"
      ]
    },
    {
      "metadata": {
        "id": "yLYJw5wfFsvC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "display(train_data.head())\n",
        "display(val_data.head())\n",
        "display(test_data.head())\n",
        "\n",
        "#train_data.drop(columns =['Alley','MiscFeature'])\n",
        "\n",
        "train_data[\"LotFrontage\"] = train_data[\"LotFrontage\"].fillna(train_data[\"LotFrontage\"].mode().iloc[0])\n",
        "train_data[\"GarageYrBlt\"] = train_data[\"GarageYrBlt\"].fillna(train_data[\"GarageYrBlt\"].mode().iloc[0])\n",
        "train_data[\"MasVnrArea\"] = train_data[\"MasVnrArea\"].fillna(train_data[\"MasVnrArea\"].mode().iloc[0])\n",
        "\n",
        "val_data[\"LotFrontage\"] = val_data[\"LotFrontage\"].fillna(train_data[\"LotFrontage\"].mode().iloc[0])\n",
        "val_data[\"GarageYrBlt\"] = val_data[\"GarageYrBlt\"].fillna(train_data[\"GarageYrBlt\"].mode().iloc[0])\n",
        "val_data[\"MasVnrArea\"] = val_data[\"MasVnrArea\"].fillna(train_data[\"MasVnrArea\"].mode().iloc[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g-R_zviufirX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_feature_groups(ames_df):\n",
        "    # Numerical Features\n",
        "    num_features = ames_df.select_dtypes(include=['int64','float64']).columns\n",
        "    num_features = num_features.drop(['Id','SalePrice']) # drop ID and SalePrice\n",
        "\n",
        "    # Categorical Features\n",
        "    cat_features = ames_df.select_dtypes(include=['object']).columns\n",
        "    return list(num_features), list(cat_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YyWipOmxfotG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_features, cat_features = get_feature_groups(train_data)\n",
        "\n",
        "# Grid of distribution plots of all numerical features\n",
        "f = pd.melt(train_data, value_vars=sorted(num_features))\n",
        "g = sns.FacetGrid(f, col='variable', col_wrap=4, sharex=False, sharey=False)\n",
        "g = g.map(sns.distplot, 'value')\n",
        "\n",
        "# Grid of frequency plots of all categoriccal features\n",
        "f = pd.melt(train_data, value_vars=sorted(cat_features))\n",
        "g = sns.FacetGrid(f, col='variable', col_wrap=4, sharex=False, sharey=False)\n",
        "plt.xticks(rotation='vertical')\n",
        "g = g.map(sns.countplot, 'value')\n",
        "[plt.setp(ax.get_xticklabels(), rotation=60) for ax in g.axes.flat]\n",
        "g.fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKemp0SzVGLA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for col in train_data.columns:\n",
        "  print(col , ': ',train_data[col].isnull().values.any())\n",
        "print('------------------------------------------------------------------------------------------------------------')\n",
        "for col in test_data.columns:\n",
        "  print(col , ': ',test_data[col].isnull().values.any())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ERAz4DnOoa07",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[stats.probplot](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.probplot.html)"
      ]
    },
    {
      "metadata": {
        "id": "hkrYcQVHQG1v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "price_train = np.array(train_data['SalePrice'].values)\n",
        "n, bins, patches = plt.hist(price_train, 100, density=True, facecolor='g', alpha=0.75)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(train_data['SalePrice'], plot=plt)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZmARJwpDoqon",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[link numpy.log1p](https://docs.scipy.org/doc/numpy/reference/generated/numpy.log1p.html)\n",
        "\n",
        "[link numpy.expm1](https://docs.scipy.org/doc/numpy/reference/generated/numpy.expm1.html#numpy.expm1)\n"
      ]
    },
    {
      "metadata": {
        "id": "Ei5egrl2j6LN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "price_train = np.log1p(np.array(train_data['SalePrice'].values))\n",
        "n, bins, patches = plt.hist(price_train, 100, density=True, facecolor='g', alpha=0.75)\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(np.log1p(train_data['SalePrice']), plot=plt)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RKPG1jvR5PqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalizer(data,is_one_dim = False):\n",
        "  if (is_one_dim):\n",
        "    min_max_scale = preprocessing.MinMaxScaler().fit(data.reshape((len(data),1)))\n",
        "  else:\n",
        "    min_max_scale = preprocessing.MinMaxScaler().fit(data)\n",
        "  return min_max_scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FggHJ_7TEEbE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_np = np.array(train_data[num_features].values)\n",
        "print(np.where(np.isnan(train_np)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e5pnmtrgQl26",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_np = np.array(train_data[num_features].values)\n",
        "train_log1p_price = np.log1p(np.array(train_data['SalePrice'].values))\n",
        "train_normalizer = normalizer(train_np)\n",
        "train_np_norm = train_normalizer.transform(train_np)\n",
        "price_normalizer = normalizer(train_log1p_price,is_one_dim = True)\n",
        "train_log1p_price_norm = price_normalizer.transform(train_log1p_price.reshape(1,len(train_log1p_price))).reshape(len(train_log1p_price))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IcHqEBgJ8h3Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lin_reg = LinearRegression().fit(train_np_norm, train_log1p_price_norm)\n",
        "train_predict_log1p_norm = lin_reg.predict(train_np_norm)\n",
        "print(lin_reg.score(train_np_norm, train_log1p_price_norm))\n",
        "\n",
        "train_predict_log1p = price_normalizer.inverse_transform(train_predict_log1p_norm.reshape((len(train_predict_log1p_norm),1))).reshape(len(train_predict_log1p_norm))\n",
        "\n",
        "delta_k_norm = np.sqrt(mean_squared_error(train_predict_log1p_norm,train_log1p_price_norm)) #mean_squared_error(train_predict_log1p_norm,train_log1p_price_norm)\n",
        "delta_k = delta_k_norm/price_normalizer.scale_\n",
        "\n",
        "print(delta_k)\n",
        "delta_x = np.mean(np.exp(train_predict_log1p)*delta_k)\n",
        "print(delta_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "21KBtRVQGgrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_np = np.array(val_data[num_features].values)\n",
        "val_log1p_price = np.log1p(np.array(val_data['SalePrice'].values))\n",
        "val_np_norm = train_normalizer.transform(val_np)\n",
        "val_log1p_price_norm = price_normalizer.transform(val_log1p_price.reshape(1,len(val_log1p_price))).reshape(len(val_log1p_price))\n",
        "\n",
        "print(lin_reg.score(val_np_norm, val_log1p_price_norm))\n",
        "\n",
        "val_predict_log1p_norm = lin_reg.predict(val_np_norm)\n",
        "val_predict_log1p = price_normalizer.inverse_transform(val_predict_log1p_norm.reshape((len(val_predict_log1p_norm),1))).reshape(len(val_predict_log1p_norm))\n",
        "\n",
        "delta_k_norm = np.sqrt(mean_squared_error(val_predict_log1p_norm,val_log1p_price_norm)) #mean_squared_error(val_predict_log1p_norm,val_log1p_price_norm)\n",
        "delta_k = delta_k_norm/price_normalizer.scale_\n",
        "print(delta_k_norm)\n",
        "print(delta_k)\n",
        "\n",
        "delta_x = np.mean(np.exp(val_predict_log1p)*delta_k)\n",
        "print(delta_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hh6LumTrQage",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "train test split"
      ]
    },
    {
      "metadata": {
        "id": "7lbjr8_D96N6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_to_sel_feature = np.vstack((train_np,val_np))\n",
        "log1p_price_all = np.hstack((train_log1p_price,val_log1p_price))\n",
        "\n",
        "data_train = np.hstack((data_to_sel_feature,log1p_price_all.reshape((len(log1p_price_all),1))))\n",
        "print(data_train.shape)\n",
        "\n",
        "corre_mat = np.corrcoef(data_train.T)\n",
        "ax = sns.heatmap(corre_mat, vmin=0, vmax=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5mIHOjuWlHt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(num_features[3])\n",
        "print(num_features[12])\n",
        "print(num_features[13])\n",
        "print(num_features[15])\n",
        "print(num_features[25])\n",
        "print(num_features[26])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HTEv_ju5WL8X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## select feature\n",
        " What happens if you reduce the amount of features to just Sex and Age? (Use logistic regression)\n"
      ]
    },
    {
      "metadata": {
        "id": "n2JU5KF3W5eY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_cut_np = np.array(train_data[['OverallQual','1stFlrSF','2ndFlrSF','GrLivArea','GarageCars','GarageArea']].values)\n",
        "\n",
        "train_cut_normalizer = normalizer(train_cut_np)\n",
        "\n",
        "train_cut_norm = train_cut_normalizer.transform(train_cut_np)\n",
        "\n",
        "lin_reg_cut = LinearRegression().fit(train_cut_norm, train_log1p_price_norm)\n",
        "train_cut_predict_log1p_norm = lin_reg_cut.predict(train_cut_norm)\n",
        "print(lin_reg_cut.score(train_cut_norm, train_log1p_price_norm))\n",
        "\n",
        "train_cut_predict_log1p = price_normalizer.inverse_transform(train_cut_predict_log1p_norm.reshape((len(train_cut_predict_log1p_norm),1))).reshape(len(train_cut_predict_log1p_norm))\n",
        "\n",
        "delta_k_norm = np.sqrt(mean_squared_error(train_cut_predict_log1p_norm,train_log1p_price_norm)) #mean_squared_error(train_cut_predict_log1p_norm,train_log1p_price_norm)\n",
        "delta_k = delta_k_norm/price_normalizer.scale_\n",
        "\n",
        "print(delta_k)\n",
        "delta_x = np.mean(np.exp(train_cut_predict_log1p)*delta_k)\n",
        "print(delta_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4AcF55BFj2p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_cut_np = np.array(val_data[['OverallQual','1stFlrSF','2ndFlrSF','GrLivArea','GarageCars','GarageArea']].values)\n",
        "\n",
        "val_cut_norm = train_cut_normalizer.transform(val_cut_np)\n",
        "\n",
        "val_cut_predict_log1p_norm = lin_reg_cut.predict(val_cut_norm)\n",
        "print(lin_reg_cut.score(val_cut_norm, val_log1p_price_norm))\n",
        "\n",
        "val_cut_predict_log1p = price_normalizer.inverse_transform(val_cut_predict_log1p_norm.reshape((len(val_cut_predict_log1p_norm),1))).reshape(len(val_cut_predict_log1p_norm))\n",
        "\n",
        "delta_k_norm = np.sqrt(mean_squared_error(val_cut_predict_log1p_norm,val_log1p_price_norm)) #mean_squared_error(val_cut_predict_log1p_norm,val_log1p_price_norm)\n",
        "delta_k = delta_k_norm/price_normalizer.scale_\n",
        "\n",
        "print(delta_k)\n",
        "delta_x = np.mean(np.exp(val_cut_predict_log1p)*delta_k)\n",
        "print(delta_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgsgog2hWZfb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## created complex feature\n",
        "\n",
        "Try adding some higher order features to your training (x2 1,x1x2,...). \n",
        "\n",
        "[polynomial feature](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zoCbOnvMGd_p",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_poly_np = preprocessing.PolynomialFeatures(2).fit_transform(train_cut_np)\n",
        "\n",
        "train_poly_normalizer = normalizer(train_poly_np)\n",
        "\n",
        "train_poly_norm = train_poly_normalizer.transform(train_poly_np)\n",
        "\n",
        "lin_reg_poly = LinearRegression().fit(train_poly_norm, train_log1p_price_norm)\n",
        "train_poly_predict_log1p_norm = lin_reg_poly.predict(train_poly_norm)\n",
        "print(lin_reg_poly.score(train_poly_norm, train_log1p_price_norm))\n",
        "\n",
        "train_poly_predict_log1p = price_normalizer.inverse_transform(train_poly_predict_log1p_norm.reshape((len(train_poly_predict_log1p_norm),1))).reshape(len(train_poly_predict_log1p_norm))\n",
        "\n",
        "delta_k_norm = np.sqrt(mean_squared_error(train_poly_predict_log1p_norm,train_log1p_price_norm)) #mean_squared_error(train_poly_predict_log1p_norm,train_log1p_price_norm)\n",
        "delta_k = delta_k_norm/price_normalizer.scale_\n",
        "\n",
        "print(delta_k)\n",
        "delta_x = np.mean(np.exp(train_cut_predict_log1p)*delta_k)\n",
        "print(delta_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iVFHLR7JGd_v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_poly_np = preprocessing.PolynomialFeatures(2).fit_transform(val_cut_np)\n",
        "\n",
        "val_poly_norm = train_poly_normalizer.transform(val_poly_np)\n",
        "\n",
        "val_poly_predict_log1p_norm = lin_reg_poly.predict(val_poly_norm)\n",
        "print(lin_reg_poly.score(val_poly_norm, val_log1p_price_norm))\n",
        "\n",
        "val_poly_predict_log1p = price_normalizer.inverse_transform(val_poly_predict_log1p_norm.reshape((len(val_poly_predict_log1p_norm),1))).reshape(len(val_poly_predict_log1p_norm))\n",
        "\n",
        "delta_k_norm = np.sqrt(mean_squared_error(val_poly_predict_log1p_norm,val_log1p_price_norm)) #mean_squared_error(val_poly_predict_log1p_norm,val_log1p_price_norm)\n",
        "delta_k = delta_k_norm/price_normalizer.scale_\n",
        "\n",
        "print(delta_k)\n",
        "delta_x = np.mean(np.exp(val_cut_predict_log1p)*delta_k)\n",
        "print(delta_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AHINxFXU7jJK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[bar chart](https://pythonspot.com/matplotlib-bar-chart/)"
      ]
    },
    {
      "metadata": {
        "id": "7vRQtt5ffG-7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "coeff_np = np.array(lin_reg_poly.coef_)\n",
        "ind = np.arange(coeff_np.shape[0])\n",
        "\n",
        "plt.bar(ind, np.absolute(coeff_np), align='center', alpha=0.5)\n",
        "plt.xticks(ind)\n",
        "plt.ylabel('values')\n",
        "plt.title('absolute of coefficient')\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z5smyWZI6sls",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[link ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet)"
      ]
    },
    {
      "metadata": {
        "id": "rDgsS5KBsZ-X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alpha_sel = 0.00001\n",
        "l1_ratio_sel = 1.0\n",
        "\n",
        "lin_reg_l1 = ElasticNet(alpha = alpha_sel, l1_ratio = l1_ratio_sel).fit(train_poly_norm, train_log1p_price_norm)\n",
        "train_predict_l1_log1p_norm = lin_reg_l1.predict(train_poly_norm)\n",
        "print(lin_reg_l1.score(train_poly_norm, train_log1p_price_norm))\n",
        "\n",
        "train_predict_l1_log1p = price_normalizer.inverse_transform(train_predict_l1_log1p_norm.reshape((len(train_predict_l1_log1p_norm),1))).reshape(len(train_predict_l1_log1p_norm))\n",
        "\n",
        "delta_k_norm = np.sqrt(mean_squared_error(train_predict_l1_log1p_norm,train_log1p_price_norm)) #mean_squared_error(train_predict_l1_log1p_norm,train_log1p_price_norm)\n",
        "delta_k = delta_k_norm/price_normalizer.scale_\n",
        "\n",
        "print(delta_k)\n",
        "delta_x = np.mean(np.exp(train_predict_l1_log1p)*delta_k)\n",
        "print(delta_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eaKIhuJoKdfM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_predict_l1_log1p_norm = lin_reg_l1.predict(val_poly_norm)\n",
        "print(lin_reg_l1.score(val_poly_norm, val_log1p_price_norm))\n",
        "\n",
        "val_predict_l1_log1p = price_normalizer.inverse_transform(val_predict_l1_log1p_norm.reshape((len(val_predict_l1_log1p_norm),1))).reshape(len(val_predict_l1_log1p_norm))\n",
        "\n",
        "delta_k_norm = np.sqrt(mean_squared_error(val_predict_l1_log1p_norm,val_log1p_price_norm)) #mean_squared_error(val_predict_l1_log1p_norm,val_log1p_price_norm)\n",
        "delta_k = delta_k_norm/price_normalizer.scale_\n",
        "\n",
        "print(delta_k)\n",
        "delta_x = np.mean(np.exp(val_predict_l1_log1p)*delta_k)\n",
        "print(delta_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WScE3o3TgVzk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "coeff_np = np.array(lin_reg_l1.coef_)\n",
        "ind = np.arange(coeff_np.shape[0])\n",
        "\n",
        "plt.bar(ind, np.absolute(coeff_np), align='center', alpha=0.5)\n",
        "plt.xticks(ind)\n",
        "plt.ylabel('values')\n",
        "plt.title('absolute of coefficient')\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "85OLvG4e6TAs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6DMbdPoYW40C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## submit your result"
      ]
    },
    {
      "metadata": {
        "id": "LnCWZOEkViHS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "bZAPhuxyaNYc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}